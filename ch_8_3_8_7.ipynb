{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adong-hood/cs200/blob/main/ch_8_3_8_7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFBwp7S5kEFS"
      },
      "source": [
        "# Chapter 8 UN Speech\n",
        "\n",
        "This notebook contains selected sections of 8.3, 8.4, 8.5 and 8.7 from chapter 8. It requires the 'un-general-debates.csv' and 'country_codes.csv' datasets. Please refer to both the Runestone book and this notebook. No Runstone book activities. Just share this note book."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWRPaCHykEFU"
      },
      "source": [
        "import string\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjdY6PN_kEG6",
        "outputId": "e40d9aa5-49df-41eb-838b-45f533d61fbf"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGF1boxrkEFY"
      },
      "source": [
        "undf = pd.read_csv('http://pluto.hood.edu/~dong/datasets/un-general-debates.csv')\n",
        "undf.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmmO89FckEF1"
      },
      "source": [
        "c_codes = pd.read_csv('http://pluto.hood.edu/~dong/datasets/country_codes.csv', encoding='iso-8859-1')\n",
        "c_codes.head(2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8.3 Merging and Tiding Data"
      ],
      "metadata": {
        "id": "o6e8v03Xivvp"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rciUblD5kEGQ"
      },
      "source": [
        "### Exercise 1:  \n",
        "\n",
        "How many countries has the `nan` value for its country name? What are the values of `code_3` of these countries? Hint: use isna() to check for NA values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ow7UB8n6kEGQ",
        "outputId": "26bbabc0-a817-46b0-8f14-7ad4476b7aa0"
      },
      "source": [
        "#\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "101"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8.4. Most and Least Common Words"
      ],
      "metadata": {
        "id": "ySKf5Be1ixrY"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYaundZZkEGw"
      },
      "source": [
        "### Exercise 2:\n",
        "Apply a lambda function on the `text` column to change the text to the lower case."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbN2QZHDkEGw"
      },
      "source": [
        "#\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFl4mffTkEHN"
      },
      "source": [
        "### Exercise 3\n",
        "\n",
        "Find out the most common and least common words in 2015 UN speeches. Make sure the most common words do not contain any non-text characters and they are interesting words, e.g. not including words such as 'must' or 'also'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3P3vyaQbkEHO"
      },
      "source": [
        "#\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D27RZtHykEFT"
      },
      "source": [
        "# 8.5. Working with Text"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# re-read for this section.\n",
        "undf = pd.read_csv('http://pluto.hood.edu/~dong/datasets/un-general-debates.csv')"
      ],
      "metadata": {
        "id": "sM_7n4pjc0e7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdoS8DXakEFg"
      },
      "source": [
        "### Exercise 4 (Q1 from 8.5):\n",
        "\n",
        "**How many rows** from the United Nations dataset have a country code that starts with ‘M’?\n",
        "\n",
        "Hint: use `str.startswith()` and count the total rows with `sum()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9eaDfslkEFl",
        "outputId": "5433fa67-f7f7-496f-a54b-bc8c07a35b41"
      },
      "source": [
        "#\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "663"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_PCyyS3kEFp"
      },
      "source": [
        "### Exercise 5 (Q2 from 8.5):  \n",
        "\n",
        "**How many country codes** from the United Nations dataset have a country code that starts with ‘M’?\n",
        "\n",
        "Notice how this is different from the last question. As each row of our dataset is a speech, the answer from last question was the number of speeches delivered by M countries, not the number of M countries.\n",
        "\n",
        "Hint: use `unique()` to find the unique country codes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmtbv3ZWkEFw",
        "outputId": "ddf605c3-4cfa-46f5-d6f1-e9cad1b75427"
      },
      "source": [
        "#"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGyQWbSykEHW"
      },
      "source": [
        "# 8.7. Sentiment Analysis of UN Speeches¶"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_bcw5EHkEHX"
      },
      "source": [
        "The Natural Language ToolKit (NLTK) provides us with many tools for sentiment analysis, e.g., [VADER (Valence Aware Dictionary and sEntiment Reasoner, not Darth Vader)](https://www.nltk.org/_modules/nltk/sentiment/vader.html). VADER performs better on normal text and does not require us to manually train a model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUzkZHcZkEHY",
        "outputId": "7af9ca91-c7a7-4f0f-ee7b-82b7ab8ca4c9"
      },
      "source": [
        "nltk.download('vader_lexicon')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eroDMe5FkEHb"
      },
      "source": [
        "from nltk import tokenize\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qR9MDbu-kEHe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23083935-8569-4da0-f939-8b91f582380c"
      },
      "source": [
        "analyzer = SentimentIntensityAnalyzer()\n",
        "score = analyzer.polarity_scores(\"I love sci-fi movies!\")\n",
        "score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'neg': 0.0, 'neu': 0.308, 'pos': 0.692, 'compound': 0.6696}"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQNtD3SekEHj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4b1c7c2-f503-453e-fc02-b0022b56cadc"
      },
      "source": [
        "score = analyzer.polarity_scores(\"I wouldn't suggest this solution to anyone.\")\n",
        "score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'neg': 0.0, 'neu': 0.656, 'pos': 0.344, 'compound': 0.3869}"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69PxZUc9MGR9"
      },
      "source": [
        "### Exercise 6.\n",
        "Which countries are the most positive in their speeches throughout the years?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amwONvmvMY4B"
      },
      "source": [
        "#"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJo6UcP4mo5I"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmn5877dmpcS"
      },
      "source": [
        "### Exercise 7.\n",
        "Which subregion is the most positive in their speeches throughout the years?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-ppJZB9fz2V"
      },
      "source": [
        "#"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}